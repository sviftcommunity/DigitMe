# -*- coding: utf-8 -*-
"""Telegram Bot DIGIT ME.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NRjwVIKsdoB-GgpkZfvAHRVC9m1RHd9u
"""

alphabet = ' -.–ê–ë–í–ì–î–ï–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–≠–Æ–Ø–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è—ë'

import os
import math
import string

import cv2
import numpy as np
import pandas as pd

import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras.backend import get_value, ctc_decode
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Nadam

import numpy as np
from tensorflow.keras.models import model_from_json

# Data preprocessing

def preprocess(img):
  for func in [resize_n_rotate, add_adaptiveThreshold]:
    img = func(img)
  return img


def resize_n_rotate(img, shape_to=(64, 800)):
  if img.shape[0] > shape_to[0] or img.shape[1] > shape_to[1]:
    shrink_multiplayer = min(math.floor(shape_to[0] / img.shape[0] * 100) / 100,
                             math.floor(shape_to[1] / img.shape[1] * 100) / 100)
    img = cv2.resize(img, None,
                     fx=shrink_multiplayer,
                     fy=shrink_multiplayer,
                     interpolation=cv2.INTER_AREA)

  img = cv2.copyMakeBorder(img, math.ceil(shape_to[0]/2) - math.ceil(img.shape[0]/2),
                           math.floor(shape_to[0]/2) - math.floor(img.shape[0]/2),
                           math.ceil(shape_to[1]/2) - math.ceil(img.shape[1]/2),
                           math.floor(shape_to[1]/2) - math.floor(img.shape[1]/2),
                           cv2.BORDER_CONSTANT, value=255)
  return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)


def add_adaptiveThreshold(img):
  return cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 10).astype('bool')


# Label encoding

def encode_text(texts):
  def _label_to_num(label, alphabet):
    label_num = []
    for ch in label:
      label_num.append(alphabet.find(ch))
    return np.array(label_num)

  alphabet = ''.join(sorted(pd.Series(texts).apply(list).apply(pd.Series).stack().unique()))

  nums = np.ones([len(texts), max([len(text) for text in texts])], dtype='int64') * len(alphabet)
  for i, text in enumerate(texts):
    nums[i][:len(text)] = _label_to_num(text, alphabet)

  return nums, alphabet

class CERMetric(tf.keras.metrics.Metric):
    """
    A custom Keras metric to compute the Character Error Rate
    """
    def __init__(self, name='CER_metric', **kwargs):
        super(CERMetric, self).__init__(name=name, **kwargs)
        self.cer_accumulator = self.add_weight(name="total_cer", initializer="zeros")
        self.counter = self.add_weight(name="cer_count", initializer="zeros")

    def update_state(self, y_true, y_pred, sample_weight=None):
        input_shape = K.shape(y_pred)
        input_length = tf.ones(shape=input_shape[0]) * K.cast(input_shape[1], 'float32')

        decode, log = K.ctc_decode(y_pred, input_length, greedy=True)

        decode = K.ctc_label_dense_to_sparse(decode[0], K.cast(input_length, 'int32'))
        y_true_sparse = K.ctc_label_dense_to_sparse(y_true, K.cast(input_length, 'int32'))
        y_true_sparse = tf.sparse.retain(y_true_sparse, tf.not_equal(y_true_sparse.values, tf.math.reduce_max(y_true_sparse.values)))

        decode = tf.sparse.retain(decode, tf.not_equal(decode.values, -1))
        distance = tf.edit_distance(decode, y_true_sparse, normalize=True)

        self.cer_accumulator.assign_add(tf.reduce_sum(distance))
        self.counter.assign_add(K.cast(len(y_true), 'float32'))

    def result(self):
        return tf.math.divide_no_nan(self.cer_accumulator, self.counter)

    def reset_state(self):
        self.cer_accumulator.assign(0.0)
        self.counter.assign(0.0)


def CTCLoss(y_true, y_pred):
    """
    Compute the training-time loss value
    """
    batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")
    input_length = tf.cast(tf.shape(y_pred)[1], dtype="int64")
    label_length = tf.cast(tf.shape(y_true)[1], dtype="int64")

    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype="int64")
    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype="int64")

    loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)
    return loss

# Decode label for single image

def num_to_label(num, alphabet):
    text = ""
    for ch in num:
        if ch == len(alphabet): # ctc blank
          break
        else:
          text += alphabet[ch]
    return text


# Decode labels for softmax matrix

def decode_text(nums):
  values = get_value(
      ctc_decode(nums, input_length=np.ones(nums.shape[0])*nums.shape[1],
                 greedy=True)[0][0])

  texts = []
  for i in range(nums.shape[0]):
    value = values[i]
    texts.append(num_to_label(value[value >= 0], alphabet))
  return texts



import telebot;
bot = telebot.TeleBot('6317466081:AAHIizRDAOuD2GuTDxaAtUCW_H9Vr3FMvoA');

@bot.message_handler(commands=['start']) #—Ä–µ–∞–≥–∏—Ä—É–µ—Ç –Ω–∞ –∫–æ–º–∞–Ω–¥—É /start
def text(message):
    bot.send_message(message.from_user.id, text = f'–ü—Ä–∏–≤–µ—Ç, *{message.from_user.first_name}*! \n\nü•∞ –¢–µ–±—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–µ—Ä–≤–∏—Å *DigitMe* –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É–∫–æ–ø–∏—Å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –æ—Ü–∏—Ñ—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Å–≤–æ—ë–º —Ñ–æ—Ç–æ, –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —è –æ—Ç–≤–µ—á—É! \n \nüìå *–ß—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, –ø—Ä–∏—Å—ã–ª–∞–π —Ñ–æ—Ç–æ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º —á—ë—Ç–∫–æ –≤–∏–¥–Ω–æ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, —Ç–∞–∫ –∫–∞–∫ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç—ã –∑–∞—Ç—Ä—É–¥–Ω—è—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ*', parse_mode= 'Markdown')

@bot.message_handler(content_types=['photo'])
def photo(message):
     fileID = message.photo[-1].file_id
     file_info = bot.get_file(fileID)
     downloaded_file = bot.download_file(file_info.file_path)
     with open("image.jpg", 'wb') as new_file:
         new_file.write(downloaded_file)
     bot.send_message(message.chat.id, text=f"–í–∞—à –∑–∞–ø—Ä–æ—Å –ø—Ä–∏–Ω—è—Ç! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ. –†–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –æ—Ç 5 –¥–æ 15 —Å–µ–∫—É–Ω–¥. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ....")
     json_file = open('model_23_01_24_2.json','r')
     model_json = json_file.read()
     json_file.close()
     new_model = model_from_json(model_json)
     new_model.load_weights("weights__23_01_24_2.h5")
     new_model.compile(optimizer=Nadam(learning_rate=0.001, clipnorm=1.0), loss=CTCLoss, metrics=[CERMetric()])
     img_X = []
     img_X.append(preprocess(cv2.imread('image.jpg', 0)))
     img_X = np.array(img_X)
     out = ""
     predicts = new_model.predict(img_X)
     predicts = decode_text(predicts)
     for i in predicts:
        if i!="[" and i!="]" and i!="'":
          out+=i
     bot.send_message(message.chat.id, text=f"<b>–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:</b> \n <code>{str(out)}</code>", parse_mode='html')

bot.polling(none_stop=True, interval=0)

